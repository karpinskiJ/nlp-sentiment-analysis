{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_apply(tweet,contractions_dict):\n",
    "    # Defining regex patterns.\n",
    "    urlPattern        = r\"((http://)[^ ]*|(https://)[^ ]*|(www\\.)[^ ]*)\"\n",
    "    userPattern       = '@[^\\s]+'\n",
    "    hashtagPattern    = '#[^\\s]+'\n",
    "    alphaPattern      = \"[^a-z0-9<>]\"\n",
    "    sequencePattern   = r\"(.)\\1\\1+\"\n",
    "    seqReplacePattern = r\"\\1\\1\"\n",
    "\n",
    "    # Defining regex for emojis\n",
    "    smileemoji        = r\"[8:=;]['`\\-]?[)d]+\"\n",
    "    sademoji          = r\"[8:=;]['`\\-]?\\(+\"\n",
    "    neutralemoji      = r\"[8:=;]['`\\-]?[\\/|l*]\"\n",
    "    lolemoji          = r\"[8:=;]['`\\-]?p+\"\n",
    "    tweet = tweet.lower()\n",
    "\n",
    "    # Replace all URls with '<url>'\n",
    "    tweet = re.sub(urlPattern,'<url>',tweet)\n",
    "    # Replace @USERNAME to '<user>'.\n",
    "    tweet = re.sub(userPattern,'<user>', tweet)\n",
    "    \n",
    "    # Replace 3 or more consecutive letters by 2 letter.\n",
    "    tweet = re.sub(sequencePattern, seqReplacePattern, tweet)\n",
    "\n",
    "    # Replace all emojis.\n",
    "    tweet = re.sub(r'<3', '<heart>', tweet)\n",
    "    tweet = re.sub(smileemoji, '<smile>', tweet)\n",
    "    tweet = re.sub(sademoji, '<sadface>', tweet)\n",
    "    tweet = re.sub(neutralemoji, '<neutralface>', tweet)\n",
    "    tweet = re.sub(lolemoji, '<lolface>', tweet)\n",
    "\n",
    "    for contraction, replacement in contractions_dict.items():\n",
    "        tweet = tweet.replace(contraction, replacement)\n",
    "\n",
    "    # Remove non-alphanumeric and symbols\n",
    "    tweet = re.sub(alphaPattern, ' ', tweet)\n",
    "\n",
    "    # Adding space on either side of '/' to seperate words (After replacing URLS).\n",
    "    tweet = re.sub(r'/', ' / ', tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/data.csv\"\n",
    "column_names = [\"sentiment\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\n",
    "df = pd.read_csv('./data/input.csv',\n",
    "                      encoding=\"ISO-8859-1\" , names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df['sentiment'].map({0: 0, 4: 1}) # Normalize target values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create constraction dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading contractions.csv and storing it as a dict.\n",
    "contractions = pd.read_csv('./data/contractions.csv', index_col='Contraction')\n",
    "contractions.index = contractions.index.str.lower()\n",
    "contractions.Meaning = contractions.Meaning.str.lower()\n",
    "contractions_dict = contractions.to_dict()['Meaning']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed_text'] = df.text.apply(lambda x: preprocess_apply(x,contractions_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"sentiment\",\"processed_text\"]].to_csv(\"data/cleaned_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viz world cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = ' '.join([text for text in df['processed_text']]) \n",
    "wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(all_words) \n",
    "plt.figure(figsize=(10, 7)) \n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\") \n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle-mirror",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
